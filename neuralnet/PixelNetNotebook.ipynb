{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Tensorflow related\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# If `%matplotlib widget` does not work then use `%matplotlib notebook`\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.widgets as widgets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading saved training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoImages=np.load(\"traindata_noimages.npy\")\n",
    "YesImages=np.load(\"traindata_yesimages.npy\")\n",
    "print(\"Shapes: {} and {}\".format(NoImages.shape,YesImages.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: creating new training images\n",
    "\n",
    "- Change the directory here to the one containing the camera image dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFilenames = glob.glob(\"framedumps/*.tga\")\n",
    "curImageIndex = 0\n",
    "\n",
    "def loadImage(filename):\n",
    "    npim = np.array(Image.open(filename))\n",
    "    npim = np.delete(npim, 3, axis=2) # delete A from RGBA\n",
    "    return npim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make sure the existing images are loaded in the `NoImages`,`YesImages` arrays\n",
    "- Empty the `newNoImages` and `newYesImages` lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNoImages = []\n",
    "newYesImages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluate the cell below to get a matplotlib interactive figure and **repeat** the following:\n",
    "- Click somewhere in the image to crop out a part and click one of the buttons to save it\n",
    "- Click next to open a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onclick(event):\n",
    "    # event.x,y is click coordinates but not in image space\n",
    "    # event.xdata,ydata is coordinates in image\n",
    "    xmin = int(event.xdata) - 20\n",
    "    xmax = int(event.xdata) + 20\n",
    "    ymin = int(event.ydata) - 20\n",
    "    ymax = int(event.ydata) + 20\n",
    "    global data\n",
    "    global fig1cropped\n",
    "    global croppedimg\n",
    "    croppedimg = data[ymin:ymax,xmin:xmax]\n",
    "    fig1cropped.imshow(croppedimg)\n",
    "    \n",
    "def onNextBtn(event):\n",
    "    global data\n",
    "    global fig1mainpic\n",
    "    global curImageIndex\n",
    "    global imageFilenames\n",
    "    data = loadImage(imageFilenames[curImageIndex])\n",
    "    fig1mainpic.imshow(data)\n",
    "    curImageIndex += 1\n",
    "    if curImageIndex >= len(imageFilenames):\n",
    "        curImageIndex = 0\n",
    "\n",
    "def onYesBtn(event):\n",
    "    global croppedimg\n",
    "    global newYesImages\n",
    "    newYesImages.append(croppedimg)\n",
    "\n",
    "def onNoBtn(event):\n",
    "    global croppedimg\n",
    "    global newNoImages\n",
    "    newNoImages.append(croppedimg)\n",
    "\n",
    "try:\n",
    "    if cid1 is not None:\n",
    "        fig1.canvas.mpl_disconnect(cid1)\n",
    "    if fig1 is not None:\n",
    "        plt.close(fig1)\n",
    "except:\n",
    "    fig1 = None\n",
    "    cid1 = None\n",
    "fig1 = plt.figure()\n",
    "cid1 = fig1.canvas.mpl_connect('button_press_event', onclick)\n",
    "fig1.canvas.layout.width ='900px'\n",
    "fig1.canvas.layout.height='800px'\n",
    "fig1mainpic = fig1.add_axes([0,   0.4, 1,   0.6]) # dist from left, dist from bottom, width, height\n",
    "fig1cropped = fig1.add_axes([0.4, 0.1, 0.2, 0.3]) # dist from left, dist from bottom, width, height\n",
    "fig1mainpic.axis('off')\n",
    "fig1cropped.axis('off')\n",
    "axYes  = fig1.add_axes([0.25-0.09, 0.05, 0.18, 0.05])\n",
    "axNo   = fig1.add_axes([0.50-0.09, 0.05, 0.18, 0.05])\n",
    "axNext = fig1.add_axes([0.75-0.09, 0.05, 0.18, 0.05])\n",
    "btnYes = widgets.Button(axYes,label='Add to YES instances')\n",
    "btnNo = widgets.Button(axNo,label='Add to NO instances')\n",
    "btnNext = widgets.Button(axNext,label='Next image')\n",
    "btnYes.on_clicked(onYesBtn)\n",
    "btnNo.on_clicked(onNoBtn)\n",
    "btnNext.on_clicked(onNextBtn)\n",
    "onNextBtn(None) #Load the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add the new images to the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NoImages = np.concatenate((NoImages,np.array(newNoImages,dtype=np.uint8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YesImages = np.concatenate((YesImages,np.array(newYesImages,dtype=np.uint8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the new array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"traindata_noimages.npy\",NoImages)\n",
    "np.save(\"traindata_yesimages.npy\",YesImages)\n",
    "print(\"Shapes: {} and {}\".format(NoImages.shape,YesImages.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network\n",
    "\n",
    "## Choose a model\n",
    "\n",
    "### Option 1: Load saved neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model definition and trained weights\n",
    "model = keras.models.load_model(\"PixelNetModel_leaky.h5\", custom_objects={'leaky_relu':tf.nn.leaky_relu})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, define a model below and load only trained weights (into another model)\n",
    "model.load_weights(\"PixelNetModel_leaky_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Define a new neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use convolutions with a 1x1 kernel to make sure every operation happens per-pixel\n",
    "model = keras.Sequential([\n",
    "    #keras.layers.Conv2D(4, kernel_size=(1,1), strides=(1, 1), padding='valid', activation=lambda x:tf.nn.leaky_relu(x, alpha=0.05), input_shape=(40,40,3)),\n",
    "    keras.layers.Conv2D(4, kernel_size=(1,1), strides=(1, 1), padding='valid', activation=tf.nn.leaky_relu, input_shape=(40,40,3)),\n",
    "    keras.layers.Conv2D(1, kernel_size=(1,1), strides=(1, 1), padding='valid', activation=tf.nn.sigmoid),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Lambda( lambda x : keras.backend.mean(x,axis=1,keepdims=True) ),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.01),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train (or continue training) the neural network\n",
    "\n",
    "- First create and shuffle training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0=np.full(len(NoImages),  0, dtype=np.uint8)\n",
    "labels1=np.full(len(YesImages), 1, dtype=np.uint8)\n",
    "# Make sure to rescale input to [0,1] range\n",
    "train_data= (1.0 / 255.0) * np.concatenate((NoImages, YesImages))\n",
    "train_labels =np.concatenate((labels0,labels1))\n",
    "\n",
    "# Shuffle\n",
    "p = np.random.permutation(len(train_data))\n",
    "train_data = train_data[p]\n",
    "train_labels = train_labels[p]\n",
    "\n",
    "print(\"Train data shape: {}\".format(train_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run training (can be called on a trained model to improve it further)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_data, train_labels, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optionally save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"PixelNetModel_1.h5\")\n",
    "model.save_weights(\"PixelNetModel_1_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance: evaluate the neural network on the image set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledNoImages = (1.0 / 255.0) * NoImages\n",
    "scaledYesImages = (1.0 / 255.0) * YesImages\n",
    "# Get the answers of all images\n",
    "noAnswers=model.predict(scaledNoImages).flatten().tolist()\n",
    "yesAnswers=model.predict(scaledYesImages).flatten().tolist()\n",
    "# Get only the first part of the model that runs per-pixel\n",
    "modelpart=keras.Sequential([model.layers[0], model.layers[1]])\n",
    "# Run it on the images\n",
    "filteredNoImages=modelpart.predict(scaledNoImages).squeeze() # Squeeze removes the 1-dimensional axis at the end\n",
    "filteredYesImages=modelpart.predict(scaledYesImages).squeeze() # Squeeze removes the 1-dimensional axis at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It might take a while for the plots to show if you plot many of them\n",
    "numToShow = 10\n",
    "\n",
    "def getColor(x):\n",
    "    x = 0.5 + 4*(x - 0.5)**3 # Amplify the things away from 0 and 1\n",
    "    return (1-x, x, 0)\n",
    "\n",
    "try:\n",
    "    plt.close(fig2)\n",
    "except:\n",
    "    fig2 = None\n",
    "\n",
    "mplnorm = colors.Normalize(vmin=0, vmax=1)\n",
    "fig2 = plt.figure(figsize=(6,0.8*numToShow))\n",
    "fig2.canvas.layout.width = \"600px\"\n",
    "fig2.canvas.layout.height = \"{}px\".format(numToShow * 80)\n",
    "subplots2 = fig2.subplots(nrows=numToShow,ncols=6)\n",
    "for i in range(numToShow):\n",
    "    for j in range(6):\n",
    "        subplots2[i,j].axis('off')\n",
    "    if i < len(NoImages):\n",
    "        subplots2[i,0].add_patch(patches.Rectangle((0,0),1,1,facecolor=getColor(noAnswers[i])))\n",
    "        subplots2[i,0].text(0.3,0.45,\"{:4.2f}\".format(noAnswers[i]))\n",
    "        subplots2[i,1].imshow(filteredNoImages[i], cmap=plt.cm.plasma, norm=mplnorm)\n",
    "        subplots2[i,2].imshow(NoImages[i])\n",
    "    if i < len(YesImages):\n",
    "        subplots2[i,3].imshow(YesImages[i])\n",
    "        subplots2[i,4].imshow(filteredYesImages[i], cmap=plt.cm.plasma, norm=mplnorm)\n",
    "        subplots2[i,5].add_patch(patches.Rectangle((0,0),1,1,facecolor=getColor(yesAnswers[i])))\n",
    "        subplots2[i,5].text(0.3,0.45,\"{:4.2f}\".format(yesAnswers[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding the Raspberry Pi tracker\n",
    "\n",
    "- Generating GLSL shader code\n",
    "\n",
    "The output of the next cell should be put in the file `src/tracker/balltrackshaders/colorfilterXXX.frag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0=model.layers[0].weights[0].numpy().squeeze()\n",
    "b0=model.layers[0].weights[1].numpy().squeeze()\n",
    "w1=model.layers[1].weights[0].numpy().squeeze()\n",
    "b1=model.layers[1].weights[1].numpy().squeeze()\n",
    "\n",
    "# Check if we should invert the output:\n",
    "# We want NO < 0 and YES > 0\n",
    "if model.layers[-1].weights[0].numpy().squeeze() < 0:\n",
    "    w1 = -w1;\n",
    "    b1 = -b1;\n",
    "\n",
    "def getGLSLmatrix(x,b):\n",
    "    out = \"mat4(\\n\"\n",
    "    for i in range(3):\n",
    "        for j in range(4):\n",
    "            out += \"{:9.4f},\".format(x[i,j])\n",
    "        out += \"  // column {}\\n\".format(i+1)\n",
    "    for j in range(3):\n",
    "        out += \"{:9.4f},\".format(b[j])\n",
    "    out += \"{:9.4f}); // last column (biases)\".format(b[3])\n",
    "    return out\n",
    "\n",
    "def getGLSLvec(x):\n",
    "    out = \"vec4(\"\n",
    "    for i in range(3):\n",
    "        out += \"{:7.4f},\".format(x[i])\n",
    "    out += \"{:7.4f});\".format(x[3])\n",
    "    return out\n",
    "\n",
    "print(\"mat4 weights0 = {}\".format(getGLSLmatrix(w0,b0)))\n",
    "print(\"vec4 weights1 = {}\".format(getGLSLvec(w1)))\n",
    "print(\"float b1 = {:7.4f};\".format(b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choose a threshold which should be used by the tracker, i.e. at what final output of the neural network should it be considered a YES. This threshold is then computed back to a number of pixels.\n",
    "- The output of the next cell should be put in `src/tracker/analysis.cpp` in the function `analysis_process_ball_buffer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "finalweight=model.layers[4].weights[0].numpy()[0,0]\n",
    "finalbias=model.layers[4].weights[1].numpy()[0]\n",
    "numpixels = (1600/finalweight) * (np.log(threshold/(1 - threshold)) - finalbias)\n",
    "if finalweight < 0:\n",
    "    numpixels = 1600 - numpixels\n",
    "scalednumpixels = int(numpixels * (255/64))\n",
    "print(\"int threshold2 = {};\".format(scalednumpixels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
